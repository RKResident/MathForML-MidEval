{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpnyKp0DnQ94"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch\n",
        "from math import floor\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "import time\n",
        "import matplotlib\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SK6ZxDUXIwPx",
        "outputId": "93b07d41-7868-4b1e-81a3-2acb063a2542"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aPujU5JAnUM0",
        "outputId": "42b4259f-0b10-48b2-9e5e-973b85abbe86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 18.3MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 495kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.70MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 12.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolution(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_shape, padding=0, dilation=1, bias=True, stride=1):\n",
        "        super().__init__()\n",
        "\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_shape = kernel_shape\n",
        "        self.padding = padding\n",
        "        self.dilation = dilation\n",
        "        self.stride = stride\n",
        "\n",
        "        if isinstance(self.padding, (int, float)):\n",
        "            self.padding = (self.padding, self.padding)\n",
        "        if isinstance(self.stride, (int, float)):\n",
        "            self.stride = (self.stride, self.stride)\n",
        "        if isinstance(self.kernel_shape, (int, float)):\n",
        "            self.kernel_shape = (self.kernel_shape, self.kernel_shape)\n",
        "\n",
        "        self.weights = nn.Parameter(torch.randn(out_channels, in_channels, *self.kernel_shape))\n",
        "        self.bias = None\n",
        "        if bias:\n",
        "            self.bias = nn.Parameter(torch.randn(out_channels))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x shape: [batch_size, in_channels, h, w]\n",
        "        windows = func.unfold(x, self.kernel_shape, dilation=self.dilation, padding=self.padding, stride=self.stride)\n",
        "        output = torch.matmul(self.weights.view(self.out_channels, -1), windows)\n",
        "        h, w = x.shape[2:]\n",
        "        output_height = floor((h + 2*self.padding[0] - self.dilation * (self.kernel_shape[0] - 1) - 1) / self.stride[0] + 1)\n",
        "        output_width = floor((w + 2*self.padding[1] - self.dilation * (self.kernel_shape[1] - 1) - 1) / self.stride[1] + 1)\n",
        "        output = func.fold(output, kernel_size=(1, 1), output_size=(output_height, output_width))\n",
        "        if self.bias is not None:\n",
        "            output += self.bias.view(1, self.out_channels, 1, 1)\n",
        "        # print(output.shape)\n",
        "        return output"
      ],
      "metadata": {
        "id": "zJ6cU4yTnYFx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MaxPool(nn.Module):\n",
        "    def __init__(self, channels, kernel_shape, padding=0, stride=1):\n",
        "        super().__init__()\n",
        "        self.channels = channels\n",
        "        self.kernel_shape = kernel_shape\n",
        "        self.padding = padding\n",
        "        self.dilation = 1\n",
        "        self.stride = stride\n",
        "        if isinstance(self.padding, (int, float)):\n",
        "            self.padding = (self.padding, self.padding)\n",
        "        if isinstance(self.stride, (int, float)):\n",
        "            self.stride = (self.stride, self.stride)\n",
        "        if isinstance(self.kernel_shape, (int, float)):\n",
        "            self.kernel_shape = (self.kernel_shape, self.kernel_shape)\n",
        "\n",
        "    def forward(self, x):\n",
        "        h, w = x.shape[2:]\n",
        "        windows = func.unfold(x, self.kernel_shape, padding=self.padding, stride=self.stride)\n",
        "        output, _ = torch.max(windows.view(windows.shape[0], self.channels, windows.shape[1]//self.channels, windows.shape[-1]), dim=2, keepdim=False)\n",
        "        output_height = floor(\n",
        "            (h + 2 * self.padding[0] - self.dilation * (self.kernel_shape[0] - 1) - 1) / self.stride[0] + 1)\n",
        "        output_width = floor(\n",
        "            (w + 2 * self.padding[1] - self.dilation * (self.kernel_shape[1] - 1) - 1) / self.stride[1] + 1)\n",
        "        output = func.fold(output, kernel_size=(1, 1), output_size=(output_height, output_width))\n",
        "        # print(output.shape)\n",
        "        return output"
      ],
      "metadata": {
        "id": "cG09sK3EnZ22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            Convolution(1, 16, 5, stride=1, padding=2, bias=True),\n",
        "            nn.ReLU(),\n",
        "            MaxPool(16, kernel_shape=2, stride=2),\n",
        "            Convolution(16, 32, 3, stride=1, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            MaxPool(32, kernel_shape=2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 32, bias=True),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 10, bias=True)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        logits = self.layers(X)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, X):\n",
        "        return torch.argmax(self.softmax(self.forward(X)), dim=1)"
      ],
      "metadata": {
        "id": "PJ2AEjU7naUV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, name, optimizer, loss_fn, epochs=10, device=\"cpu\"):\n",
        "    EPOCHS = epochs\n",
        "    val_best = 0\n",
        "    train_loss, val_acc = [], []\n",
        "    for epoch in range(EPOCHS):\n",
        "        running_loss = 0.0\n",
        "        for i, batch_data in enumerate(trainloader, 0):\n",
        "            inputs, labels = batch_data\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            if ((i+1)%100 == 0):\n",
        "                print(\"       \", i+1, \"Train batch\")\n",
        "        train_loss.append(running_loss/len(trainloader))\n",
        "        with torch.inference_mode():\n",
        "            corr = overall = 0\n",
        "            for i, batch in enumerate(testloader):\n",
        "                images, truth = batch\n",
        "                images = images.to(device)\n",
        "                truth = truth.to(device)\n",
        "                output = model.predict(images)\n",
        "                corr += (output == truth).sum().item()\n",
        "                overall += len(truth)\n",
        "            print(f\"Epoch {epoch+1} Test Accuracy: {corr/overall}\")\n",
        "            val_acc.append(corr/overall)\n",
        "            if corr/overall > val_best:\n",
        "                val_best = corr/overall\n",
        "                torch.save(model.state_dict(), f'/content/{name}.pth')\n",
        "                print('Saved new best')\n",
        "        print(f\"Epoch: {epoch+1}, loss: {running_loss/len(trainloader)}\\n\")\n",
        "    return train_loss, val_acc"
      ],
      "metadata": {
        "id": "g0ou6GQQneBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ConvNet2()\n",
        "model.to(device)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "print(len(trainloader))\n",
        "train_loss, val_acc = train(model, 'conv2', epochs=20, optimizer=optimizer, loss_fn=loss_fn, device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZbOlWU7Gngr4",
        "outputId": "80fd70f1-3966-4638-bff7-56abe2ec332e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "938\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 1 Test Accuracy: 0.9824\n",
            "Saved new best\n",
            "Epoch: 1, loss: 0.23272685066008492\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 2 Test Accuracy: 0.9841\n",
            "Saved new best\n",
            "Epoch: 2, loss: 0.05144226897472162\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 3 Test Accuracy: 0.9861\n",
            "Saved new best\n",
            "Epoch: 3, loss: 0.03429233625658782\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 4 Test Accuracy: 0.9854\n",
            "Epoch: 4, loss: 0.025511224652384357\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 5 Test Accuracy: 0.9843\n",
            "Epoch: 5, loss: 0.019599399488068808\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 6 Test Accuracy: 0.982\n",
            "Epoch: 6, loss: 0.016344809599631804\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 7 Test Accuracy: 0.986\n",
            "Epoch: 7, loss: 0.012870316680647116\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 8 Test Accuracy: 0.9868\n",
            "Saved new best\n",
            "Epoch: 8, loss: 0.011268582037563295\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 9 Test Accuracy: 0.986\n",
            "Epoch: 9, loss: 0.009627076371838569\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 10 Test Accuracy: 0.987\n",
            "Saved new best\n",
            "Epoch: 10, loss: 0.008239552293817435\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 11 Test Accuracy: 0.986\n",
            "Epoch: 11, loss: 0.007079582520230521\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 12 Test Accuracy: 0.9877\n",
            "Saved new best\n",
            "Epoch: 12, loss: 0.006307566971756546\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 13 Test Accuracy: 0.9882\n",
            "Saved new best\n",
            "Epoch: 13, loss: 0.005521873220407024\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 14 Test Accuracy: 0.9873\n",
            "Epoch: 14, loss: 0.005203135892506926\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 15 Test Accuracy: 0.9874\n",
            "Epoch: 15, loss: 0.005539634154785108\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 16 Test Accuracy: 0.9873\n",
            "Epoch: 16, loss: 0.0038446043268614534\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 17 Test Accuracy: 0.9858\n",
            "Epoch: 17, loss: 0.0039487397881864195\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 18 Test Accuracy: 0.9873\n",
            "Epoch: 18, loss: 0.0038703697317925504\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 19 Test Accuracy: 0.9865\n",
            "Epoch: 19, loss: 0.004055310716045139\n",
            "\n",
            "        100 Train batch\n",
            "        200 Train batch\n",
            "        300 Train batch\n",
            "        400 Train batch\n",
            "        500 Train batch\n",
            "        600 Train batch\n",
            "        700 Train batch\n",
            "        800 Train batch\n",
            "        900 Train batch\n",
            "Epoch 20 Test Accuracy: 0.9881\n",
            "Epoch: 20, loss: 0.0026913690062584077\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(1)\n",
        "plt.plot(range(len(train_loss)), train_loss)\n",
        "plt.title(\"Trian loss over epochs\")\n",
        "plt.figure(2)\n",
        "plt.plot(range(len(val_acc)), val_acc)\n",
        "plt.title(\"Val Accuracy over epochs\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6T5GDXK1n2cT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "How the model would be implemented using nn.Conv2D and nn.MaxPool2D\n",
        "\"\"\"\n",
        "class ConvNet2_speedup(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 5, stride=1, padding=2, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Conv2d(16, 32, 3, stride=1, padding=1, bias=True),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * 7 * 7, 32, bias=True),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(32, 10, bias=True)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, X):\n",
        "        logits = self.layers(X)\n",
        "        return logits\n",
        "\n",
        "    def predict(self, X):\n",
        "        return torch.argmax(self.softmax(self.forward(X)), dim=1)\n"
      ],
      "metadata": {
        "id": "jdoyBxRxoGIh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Benchmarking it against our implementation shows that this version takes 45 seconds per epoch, against 108 seconds by our implementation"
      ],
      "metadata": {
        "id": "yA-uHladoDeq"
      }
    }
  ]
}