{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "An1tFl-4J9jl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as func\n",
        "import torch\n",
        "from math import floor, sqrt\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import optim\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrFFNNGeOhQP",
        "outputId": "ef724076-88ea-439b-ba99-f61f9ef8593d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Setup device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXwLTanqOjnf",
        "outputId": "679d5ff2-4220-4a08-b305-58572d0a0b74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.9MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 459kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 4.25MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 10.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Data preparation\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=512, shuffle=False)\n",
        "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=512, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JEisPmnOk60"
      },
      "outputs": [],
      "source": [
        "# Custom activation function: x * erf(x/sqrt(2))\n",
        "# SGELU - Symmetric Gaussian Error Linear Unit\n",
        "class SGELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sqrt2 = sqrt(2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.erf(x / self.sqrt2)\n",
        "\n",
        "\n",
        "# Learnable custom activation: alpha * x * erf(x/sqrt(2))\n",
        "class AdaSGELU(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.sqrt2 = sqrt(2)\n",
        "        self.alpha = nn.Parameter(torch.ones(1))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.alpha * x * torch.erf(x / self.sqrt2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzMQq_9pOvs8"
      },
      "outputs": [],
      "source": [
        "# Model definition\n",
        "class MnistTest(nn.Module):\n",
        "    def __init__(self, activation):\n",
        "        super().__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(28 * 28, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            activation(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, 10)\n",
        "        )\n",
        "        self.softmax = nn.Softmax(dim=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "    def predict(self, x):\n",
        "        return torch.argmax(self.softmax(self.layers(x)), dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "It2xbXHXOzqj"
      },
      "outputs": [],
      "source": [
        "# train_func\n",
        "def train_epoch(model, loader, optimizer, criterion):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for data, target in loader:\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    return total_loss / len(loader)\n",
        "\n",
        "\n",
        "# Evaluation function\n",
        "def evaluate(model, loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            total_loss += loss.item()\n",
        "            pred = model.predict(data)\n",
        "            correct += (pred == target).sum().item()\n",
        "            total += target.size(0)\n",
        "    return total_loss / len(loader), correct / total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dSWgZMsTO2PN"
      },
      "outputs": [],
      "source": [
        "# Benchmark function\n",
        "def benchmark_activation(activation_name, activation_class, epochs=20):\n",
        "    print(f\"\\n{'=' * 60}\")\n",
        "    print(f\"Training with {activation_name}\")\n",
        "    print(f\"{'=' * 60}\")\n",
        "\n",
        "    model = MnistTest(activation_class).to(device)\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    results = {\n",
        "        'activation': activation_name,\n",
        "        'epochs': [],\n",
        "        'train_loss': [],\n",
        "        'test_loss': [],\n",
        "        'test_accuracy': []\n",
        "    }\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        train_loss = train_epoch(model, trainloader, optimizer, criterion)\n",
        "        test_loss, test_acc = evaluate(model, testloader, criterion)\n",
        "\n",
        "        results['epochs'].append(epoch + 1)\n",
        "        results['train_loss'].append(train_loss)\n",
        "        results['test_loss'].append(test_loss)\n",
        "        results['test_accuracy'].append(test_acc)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1:2d}/{epochs} | \"\n",
        "              f\"Train Loss: {train_loss:.4f} | \"\n",
        "              f\"Test Loss: {test_loss:.4f} | \"\n",
        "              f\"Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "    elapsed_time = time.time() - start_time\n",
        "    results['training_time'] = elapsed_time\n",
        "    print(f\"\\nTraining completed in {elapsed_time:.2f} seconds\")\n",
        "    print(f\"Final Test Accuracy: {results['test_accuracy'][-1]:.4f}\")\n",
        "\n",
        "    return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uo1eko0KO7SL",
        "outputId": "d36ddcdb-ea6a-4fc4-b355-69afc98ad8a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No existing results found. Will train all activations.\n",
            "\n",
            "============================================================\n",
            "Training with ReLU\n",
            "============================================================\n",
            "Epoch  1/20 | Train Loss: 0.6172 | Test Loss: 0.2708 | Test Acc: 0.9263\n",
            "Epoch  2/20 | Train Loss: 0.3153 | Test Loss: 0.2084 | Test Acc: 0.9424\n",
            "Epoch  3/20 | Train Loss: 0.2636 | Test Loss: 0.1790 | Test Acc: 0.9504\n",
            "Epoch  4/20 | Train Loss: 0.2359 | Test Loss: 0.1603 | Test Acc: 0.9536\n",
            "Epoch  5/20 | Train Loss: 0.2150 | Test Loss: 0.1445 | Test Acc: 0.9595\n",
            "Epoch  6/20 | Train Loss: 0.1975 | Test Loss: 0.1374 | Test Acc: 0.9604\n",
            "Epoch  7/20 | Train Loss: 0.1841 | Test Loss: 0.1269 | Test Acc: 0.9647\n",
            "Epoch  8/20 | Train Loss: 0.1767 | Test Loss: 0.1223 | Test Acc: 0.9660\n",
            "Epoch  9/20 | Train Loss: 0.1681 | Test Loss: 0.1137 | Test Acc: 0.9678\n",
            "Epoch 10/20 | Train Loss: 0.1576 | Test Loss: 0.1112 | Test Acc: 0.9678\n",
            "Epoch 11/20 | Train Loss: 0.1520 | Test Loss: 0.1073 | Test Acc: 0.9700\n",
            "Epoch 12/20 | Train Loss: 0.1457 | Test Loss: 0.1056 | Test Acc: 0.9698\n",
            "Epoch 13/20 | Train Loss: 0.1385 | Test Loss: 0.1022 | Test Acc: 0.9699\n",
            "Epoch 14/20 | Train Loss: 0.1366 | Test Loss: 0.0992 | Test Acc: 0.9711\n",
            "Epoch 15/20 | Train Loss: 0.1334 | Test Loss: 0.0999 | Test Acc: 0.9723\n",
            "Epoch 16/20 | Train Loss: 0.1277 | Test Loss: 0.0956 | Test Acc: 0.9719\n",
            "Epoch 17/20 | Train Loss: 0.1255 | Test Loss: 0.0942 | Test Acc: 0.9739\n",
            "Epoch 18/20 | Train Loss: 0.1186 | Test Loss: 0.0943 | Test Acc: 0.9729\n",
            "Epoch 19/20 | Train Loss: 0.1171 | Test Loss: 0.0901 | Test Acc: 0.9739\n",
            "Epoch 20/20 | Train Loss: 0.1141 | Test Loss: 0.0917 | Test Acc: 0.9738\n",
            "\n",
            "Training completed in 267.47 seconds\n",
            "Final Test Accuracy: 0.9738\n",
            "\n",
            "============================================================\n",
            "Training with ELU\n",
            "============================================================\n",
            "Epoch  1/20 | Train Loss: 0.5266 | Test Loss: 0.2936 | Test Acc: 0.9189\n",
            "Epoch  2/20 | Train Loss: 0.3181 | Test Loss: 0.2496 | Test Acc: 0.9272\n",
            "Epoch  3/20 | Train Loss: 0.2826 | Test Loss: 0.2210 | Test Acc: 0.9375\n",
            "Epoch  4/20 | Train Loss: 0.2571 | Test Loss: 0.2023 | Test Acc: 0.9419\n",
            "Epoch  5/20 | Train Loss: 0.2373 | Test Loss: 0.1881 | Test Acc: 0.9469\n",
            "Epoch  6/20 | Train Loss: 0.2275 | Test Loss: 0.1777 | Test Acc: 0.9490\n",
            "Epoch  7/20 | Train Loss: 0.2150 | Test Loss: 0.1658 | Test Acc: 0.9516\n",
            "Epoch  8/20 | Train Loss: 0.2070 | Test Loss: 0.1620 | Test Acc: 0.9532\n",
            "Epoch  9/20 | Train Loss: 0.1974 | Test Loss: 0.1544 | Test Acc: 0.9555\n",
            "Epoch 10/20 | Train Loss: 0.1900 | Test Loss: 0.1500 | Test Acc: 0.9563\n",
            "Epoch 11/20 | Train Loss: 0.1852 | Test Loss: 0.1440 | Test Acc: 0.9596\n",
            "Epoch 12/20 | Train Loss: 0.1795 | Test Loss: 0.1365 | Test Acc: 0.9608\n",
            "Epoch 13/20 | Train Loss: 0.1729 | Test Loss: 0.1318 | Test Acc: 0.9626\n",
            "Epoch 14/20 | Train Loss: 0.1702 | Test Loss: 0.1316 | Test Acc: 0.9609\n",
            "Epoch 15/20 | Train Loss: 0.1667 | Test Loss: 0.1247 | Test Acc: 0.9644\n",
            "Epoch 16/20 | Train Loss: 0.1604 | Test Loss: 0.1246 | Test Acc: 0.9636\n",
            "Epoch 17/20 | Train Loss: 0.1591 | Test Loss: 0.1243 | Test Acc: 0.9652\n",
            "Epoch 18/20 | Train Loss: 0.1515 | Test Loss: 0.1176 | Test Acc: 0.9658\n",
            "Epoch 19/20 | Train Loss: 0.1492 | Test Loss: 0.1158 | Test Acc: 0.9666\n",
            "Epoch 20/20 | Train Loss: 0.1460 | Test Loss: 0.1146 | Test Acc: 0.9685\n",
            "\n",
            "Training completed in 261.74 seconds\n",
            "Final Test Accuracy: 0.9685\n",
            "\n",
            "============================================================\n",
            "Training with GELU\n",
            "============================================================\n",
            "Epoch  1/20 | Train Loss: 0.5894 | Test Loss: 0.2666 | Test Acc: 0.9294\n",
            "Epoch  2/20 | Train Loss: 0.2940 | Test Loss: 0.1986 | Test Acc: 0.9435\n",
            "Epoch  3/20 | Train Loss: 0.2412 | Test Loss: 0.1670 | Test Acc: 0.9512\n",
            "Epoch  4/20 | Train Loss: 0.2103 | Test Loss: 0.1492 | Test Acc: 0.9573\n",
            "Epoch  5/20 | Train Loss: 0.1928 | Test Loss: 0.1334 | Test Acc: 0.9625\n",
            "Epoch  6/20 | Train Loss: 0.1731 | Test Loss: 0.1237 | Test Acc: 0.9654\n",
            "Epoch  7/20 | Train Loss: 0.1615 | Test Loss: 0.1158 | Test Acc: 0.9675\n",
            "Epoch  8/20 | Train Loss: 0.1504 | Test Loss: 0.1113 | Test Acc: 0.9704\n",
            "Epoch  9/20 | Train Loss: 0.1437 | Test Loss: 0.1046 | Test Acc: 0.9696\n",
            "Epoch 10/20 | Train Loss: 0.1349 | Test Loss: 0.1003 | Test Acc: 0.9727\n",
            "Epoch 11/20 | Train Loss: 0.1268 | Test Loss: 0.0982 | Test Acc: 0.9724\n",
            "Epoch 12/20 | Train Loss: 0.1233 | Test Loss: 0.0957 | Test Acc: 0.9723\n",
            "Epoch 13/20 | Train Loss: 0.1185 | Test Loss: 0.0944 | Test Acc: 0.9740\n",
            "Epoch 14/20 | Train Loss: 0.1132 | Test Loss: 0.0901 | Test Acc: 0.9737\n",
            "Epoch 15/20 | Train Loss: 0.1096 | Test Loss: 0.0910 | Test Acc: 0.9737\n",
            "Epoch 16/20 | Train Loss: 0.1041 | Test Loss: 0.0880 | Test Acc: 0.9743\n",
            "Epoch 17/20 | Train Loss: 0.1001 | Test Loss: 0.0867 | Test Acc: 0.9755\n",
            "Epoch 18/20 | Train Loss: 0.0961 | Test Loss: 0.0880 | Test Acc: 0.9739\n",
            "Epoch 19/20 | Train Loss: 0.0920 | Test Loss: 0.0864 | Test Acc: 0.9747\n",
            "Epoch 20/20 | Train Loss: 0.0886 | Test Loss: 0.0852 | Test Acc: 0.9737\n",
            "\n",
            "Training completed in 257.96 seconds\n",
            "Final Test Accuracy: 0.9737\n",
            "\n",
            "============================================================\n",
            "Training with SGELU\n",
            "============================================================\n",
            "Epoch  1/20 | Train Loss: 0.7374 | Test Loss: 0.2611 | Test Acc: 0.9479\n",
            "Epoch  2/20 | Train Loss: 0.3098 | Test Loss: 0.1616 | Test Acc: 0.9617\n",
            "Epoch  3/20 | Train Loss: 0.2404 | Test Loss: 0.1290 | Test Acc: 0.9671\n",
            "Epoch  4/20 | Train Loss: 0.2080 | Test Loss: 0.1116 | Test Acc: 0.9712\n",
            "Epoch  5/20 | Train Loss: 0.1865 | Test Loss: 0.1047 | Test Acc: 0.9714\n",
            "Epoch  6/20 | Train Loss: 0.1711 | Test Loss: 0.0966 | Test Acc: 0.9729\n",
            "Epoch  7/20 | Train Loss: 0.1622 | Test Loss: 0.0919 | Test Acc: 0.9736\n",
            "Epoch  8/20 | Train Loss: 0.1553 | Test Loss: 0.0852 | Test Acc: 0.9763\n",
            "Epoch  9/20 | Train Loss: 0.1454 | Test Loss: 0.0844 | Test Acc: 0.9771\n",
            "Epoch 10/20 | Train Loss: 0.1386 | Test Loss: 0.0819 | Test Acc: 0.9781\n",
            "Epoch 11/20 | Train Loss: 0.1370 | Test Loss: 0.0788 | Test Acc: 0.9778\n",
            "Epoch 12/20 | Train Loss: 0.1305 | Test Loss: 0.0796 | Test Acc: 0.9782\n",
            "Epoch 13/20 | Train Loss: 0.1281 | Test Loss: 0.0751 | Test Acc: 0.9799\n",
            "Epoch 14/20 | Train Loss: 0.1256 | Test Loss: 0.0765 | Test Acc: 0.9780\n",
            "Epoch 15/20 | Train Loss: 0.1221 | Test Loss: 0.0751 | Test Acc: 0.9790\n",
            "Epoch 16/20 | Train Loss: 0.1170 | Test Loss: 0.0751 | Test Acc: 0.9792\n",
            "Epoch 17/20 | Train Loss: 0.1151 | Test Loss: 0.0739 | Test Acc: 0.9799\n",
            "Epoch 18/20 | Train Loss: 0.1164 | Test Loss: 0.0713 | Test Acc: 0.9798\n",
            "Epoch 19/20 | Train Loss: 0.1096 | Test Loss: 0.0713 | Test Acc: 0.9798\n",
            "Epoch 20/20 | Train Loss: 0.1115 | Test Loss: 0.0722 | Test Acc: 0.9782\n",
            "\n",
            "Training completed in 258.01 seconds\n",
            "Final Test Accuracy: 0.9782\n",
            "\n",
            "============================================================\n",
            "Training with AdaSGELU\n",
            "============================================================\n",
            "Epoch  1/20 | Train Loss: 1.8199 | Test Loss: 0.9493 | Test Acc: 0.8880\n",
            "Epoch  2/20 | Train Loss: 0.6040 | Test Loss: 0.3009 | Test Acc: 0.9414\n",
            "Epoch  3/20 | Train Loss: 0.3206 | Test Loss: 0.1866 | Test Acc: 0.9572\n",
            "Epoch  4/20 | Train Loss: 0.2504 | Test Loss: 0.1457 | Test Acc: 0.9626\n",
            "Epoch  5/20 | Train Loss: 0.2145 | Test Loss: 0.1242 | Test Acc: 0.9667\n",
            "Epoch  6/20 | Train Loss: 0.1983 | Test Loss: 0.1104 | Test Acc: 0.9685\n",
            "Epoch  7/20 | Train Loss: 0.1816 | Test Loss: 0.1046 | Test Acc: 0.9721\n",
            "Epoch  8/20 | Train Loss: 0.1698 | Test Loss: 0.0990 | Test Acc: 0.9723\n",
            "Epoch  9/20 | Train Loss: 0.1634 | Test Loss: 0.0936 | Test Acc: 0.9735\n",
            "Epoch 10/20 | Train Loss: 0.1561 | Test Loss: 0.0896 | Test Acc: 0.9746\n",
            "Epoch 11/20 | Train Loss: 0.1468 | Test Loss: 0.0863 | Test Acc: 0.9761\n",
            "Epoch 12/20 | Train Loss: 0.1468 | Test Loss: 0.0871 | Test Acc: 0.9748\n",
            "Epoch 13/20 | Train Loss: 0.1386 | Test Loss: 0.0841 | Test Acc: 0.9773\n",
            "Epoch 14/20 | Train Loss: 0.1373 | Test Loss: 0.0807 | Test Acc: 0.9775\n",
            "Epoch 15/20 | Train Loss: 0.1346 | Test Loss: 0.0825 | Test Acc: 0.9773\n",
            "Epoch 16/20 | Train Loss: 0.1304 | Test Loss: 0.0788 | Test Acc: 0.9777\n",
            "Epoch 17/20 | Train Loss: 0.1267 | Test Loss: 0.0802 | Test Acc: 0.9777\n",
            "Epoch 18/20 | Train Loss: 0.1223 | Test Loss: 0.0754 | Test Acc: 0.9784\n",
            "Epoch 19/20 | Train Loss: 0.1249 | Test Loss: 0.0757 | Test Acc: 0.9793\n",
            "Epoch 20/20 | Train Loss: 0.1188 | Test Loss: 0.0791 | Test Acc: 0.9782\n",
            "\n",
            "Training completed in 258.83 seconds\n",
            "Final Test Accuracy: 0.9782\n"
          ]
        }
      ],
      "source": [
        "activations = {\n",
        "    'ReLU': nn.ReLU,\n",
        "    'ELU': nn.ELU,\n",
        "    'GELU': nn.GELU,\n",
        "    'SGELU': SGELU,\n",
        "    'AdaSGELU': AdaSGELU,\n",
        "}\n",
        "\n",
        "# Load existing results if they exist\n",
        "output_file = 'activation_benchmark_results.json'\n",
        "try:\n",
        "    with open(output_file, 'r') as f:\n",
        "        all_results = json.load(f)\n",
        "    print(f\"Loaded existing results from {output_file}\")\n",
        "    print(f\"Already trained: {list(all_results.keys())}\")\n",
        "except FileNotFoundError:\n",
        "    all_results = {}\n",
        "    print(f\"No existing results found. Will train all activations.\")\n",
        "\n",
        "# Only train activations that haven't been trained yet\n",
        "for name, activation_class in activations.items():\n",
        "    if name in all_results:\n",
        "        print(f\"\\nSkipping {name} (already trained)\")\n",
        "    else:\n",
        "        results = benchmark_activation(name, activation_class, epochs=20)\n",
        "        all_results[name] = results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aFShIfFoPF0v",
        "outputId": "51eae1e2-f4a4-44bf-b41e-de6f4523dee9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "Benchmark Summary\n",
            "============================================================\n",
            "ReLU                 | Final Acc: 0.9738 | Time: 267.47s\n",
            "ELU                  | Final Acc: 0.9685 | Time: 261.74s\n",
            "GELU                 | Final Acc: 0.9737 | Time: 257.96s\n",
            "SGELU                | Final Acc: 0.9782 | Time: 258.01s\n",
            "AdaSGELU             | Final Acc: 0.9782 | Time: 258.83s\n",
            "\n",
            "Results saved to activation_benchmark_results.json\n"
          ]
        }
      ],
      "source": [
        "# Save results to JSON\n",
        "output_file = 'activation_benchmark_results.json'\n",
        "with open(output_file, 'w') as f:\n",
        "    json.dump(all_results, f, indent=4)\n",
        "\n",
        "print(f\"\\n{'=' * 60}\")\n",
        "print(f\"Benchmark Summary\")\n",
        "print(f\"{'=' * 60}\")\n",
        "for name, results in all_results.items():\n",
        "    print(f\"{name:20s} | Final Acc: {results['test_accuracy'][-1]:.4f} | \"\n",
        "          f\"Time: {results['training_time']:.2f}s\")\n",
        "\n",
        "print(f\"\\nResults saved to {output_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGn6tHf0PJLH"
      },
      "source": [
        "Visualizing results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "QjpsmvxTPH1a",
        "outputId": "167a7481-38dc-4fc5-aee0-6a346a8ffb15"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'activation_benchmark_results.json'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3552190127.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the benchmark results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'activation_benchmark_results.json'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Set up the plot style\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'activation_benchmark_results.json'"
          ]
        }
      ],
      "source": [
        "# Load the benchmark results\n",
        "with open('activation_benchmark_results.json', 'r') as f:\n",
        "    results = json.load(f)\n",
        "\n",
        "# Set up the plot style\n",
        "plt.style.use('seaborn-v0_8-darkgrid')\n",
        "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', 'black', 'pink']\n",
        "\n",
        "# Create figure with 2 subplots\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Test Accuracy\n",
        "ax1 = axes[0]\n",
        "for i, (name, data) in enumerate(results.items()):\n",
        "    epochs = data['epochs']\n",
        "    test_acc = [acc * 100 for acc in data['test_accuracy']]  # Convert to percentage\n",
        "    ax1.plot(epochs, test_acc, marker='o', linewidth=2,\n",
        "             markersize=4, label=name, color=colors[i])\n",
        "\n",
        "ax1.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax1.set_ylabel('Test Accuracy (%)', fontsize=12, fontweight='bold')\n",
        "ax1.set_title('Test Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "ax1.legend(loc='lower right', fontsize=10)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "ax1.set_xlim(1, 20)\n",
        "\n",
        "# Plot 2: Training Loss\n",
        "ax2 = axes[1]\n",
        "for i, (name, data) in enumerate(results.items()):\n",
        "    epochs = data['epochs']\n",
        "    train_loss = data['train_loss']\n",
        "    ax2.plot(epochs, train_loss, marker='o', linewidth=2,\n",
        "             markersize=4, label=name, color=colors[i])\n",
        "\n",
        "ax2.set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
        "ax2.set_ylabel('Training Loss', fontsize=12, fontweight='bold')\n",
        "ax2.set_title('Training Loss Comparison', fontsize=14, fontweight='bold')\n",
        "ax2.legend(loc='upper right', fontsize=10)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_xlim(1, 20)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('activation_comparison.png', dpi=300, bbox_inches='tight')\n",
        "print(\"Plot saved as 'activation_comparison.png'\")\n",
        "plt.show()\n",
        "\n",
        "# Print final statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"Final Performance Summary\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Activation':<20} {'Final Acc (%)':<15} {'Final Train Loss':<20} {'Time (s)'}\")\n",
        "print(\"-\"*60)\n",
        "for name, data in results.items():\n",
        "    final_acc = data['test_accuracy'][-1] * 100\n",
        "    final_train_loss = data['train_loss'][-1]\n",
        "    train_time = data['training_time']\n",
        "    print(f\"{name:<20} {final_acc:<15.2f} {final_train_loss:<20.4f} {train_time:.2f}\")\n",
        "\n",
        "# Find best performing activation\n",
        "best_activation = max(results.items(), key=lambda x: x[1]['test_accuracy'][-1])\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(f\"Best Performing Activation: {best_activation[0]}\")\n",
        "print(f\"Final Test Accuracy: {best_activation[1]['test_accuracy'][-1] * 100:.2f}%\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Autoencoder test"
      ],
      "metadata": {
        "id": "-rEAY8OgqF0w"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}